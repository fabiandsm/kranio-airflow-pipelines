# Apache Airflow â€“ DAGs Funcionales y AutomatizaciÃ³n de Pipelines

Este repositorio contiene la implementaciÃ³n de **DAGs funcionales en Apache Airflow**, desarrollados como ejercicios prÃ¡cticos para comprender la creaciÃ³n, ejecuciÃ³n y monitoreo de workflows basados en **grafos dirigidos acÃ­clicos (DAGs)**.

El proyecto fue desplegado utilizando **Apache Airflow 2.9.3 sobre Docker en Windows**, siguiendo buenas prÃ¡cticas de configuraciÃ³n, diagnÃ³stico y orquestaciÃ³n de pipelines.

---

## ğŸ“Œ Objetivo del ejercicio

- Instalar y configurar Apache Airflow.
- Crear DAGs con mÃºltiples tareas.
- Definir dependencias simples y complejas entre tareas.
- Ejecutar y monitorear DAGs desde la interfaz web.
- Verificar logs de ejecuciÃ³n.
- Comprender el uso de operadores bÃ¡sicos de Airflow.

---

## ğŸ› ï¸ TecnologÃ­as utilizadas

- **Python 3.12**
- **Apache Airflow 2.9.3**
- **Docker & Docker Compose**
- **PostgreSQL 15**
- **Windows 11**

---

## ğŸ“ Estructura del proyecto

```
airflow_docker/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ saludo_diario.py
â”‚   â”œâ”€â”€ dependencias_complejas.py
â”‚   â”œâ”€â”€ flujo_saludo_diario.png
â”‚   â”œâ”€â”€ operadores_sensores.py
â”‚   â”œâ”€â”€ operadores_sensores.png
â”‚   â”œâ”€â”€ monitoreo_alertas.py
â”‚   â”œâ”€â”€ monitoreo_alertas.png
â”‚   â””â”€â”€ README.md
â””â”€â”€ docker-compose.yml
```

---

## ğŸš€ DAG 1: Saludo Diario

### DescripciÃ³n

DAG introductorio que permite validar la correcta instalaciÃ³n y funcionamiento de Apache Airflow.

- **DAG ID**: `saludo_diario`
- **Schedule**: `@daily`
- **Catchup**: deshabilitado

### Flujo de ejecuciÃ³n

```
tarea_bash â†’ tarea_python â†’ tarea_esperar
```

### Resultado esperado

- EjecuciÃ³n secuencial de las tareas.
- VisualizaciÃ³n correcta del flujo en Graph View.
- Logs accesibles desde la interfaz web.

---

## ğŸ§© DAG 2: Pipeline de Ventas con Dependencias Complejas

Como parte del ejercicio de automatizaciÃ³n, se implementÃ³ un DAG que modela un **pipeline ETL de ventas**, incorporando ejecuciÃ³n paralela y sincronizaciÃ³n explÃ­cita entre tareas.

- **DAG ID**: `pipeline_ventas_complejo`
- **Schedule**: `@daily`
- **Catchup**: deshabilitado

---

### 1ï¸âƒ£ VisualizaciÃ³n del grafo de dependencias

El DAG fue visualizado utilizando **Graph View** en la interfaz web de Apache Airflow, permitiendo verificar visualmente el flujo de ejecuciÃ³n y las dependencias entre tareas.

**Flujo verificado:**

```
preparar_entorno â†’ [extraer_api_ventas, extraer_db_productos]
extraer_api_ventas â†’ validar_datos_api â†’ transformar_ventas â†˜
extraer_db_productos â†’ validar_datos_db â†’ transformar_productos â†˜
                                   join_ventas_productos
                                             â†“
                                    cargar_data_warehouse
                                             â†“
                                   enviar_reporte_ejecucion
```

El grafo confirma ejecuciÃ³n paralela en las etapas de extracciÃ³n y validaciÃ³n, seguida de una sincronizaciÃ³n explÃ­cita en la etapa de *join* antes de la carga final.

---

### 2ï¸âƒ£ Pruebas de ejecuciÃ³n del DAG

Para validar el correcto funcionamiento del pipeline se realizaron los siguientes escenarios:

**Prueba del DAG sin scheduler:**
```bash
airflow dags test pipeline_ventas_complejo 2024-01-01
```

**EjecuciÃ³n manual del DAG:**
```bash
airflow dags trigger pipeline_ventas_complejo
```

**RevisiÃ³n de logs de la tarea final:**
```bash
airflow tasks logs pipeline_ventas_complejo enviar_reporte_ejecucion 2024-01-01
```

Los logs confirman que el pipeline se ejecuta correctamente hasta la generaciÃ³n del reporte final.

---

### 3ï¸âƒ£ VerificaciÃ³n conceptual

**a) ElecciÃ³n entre PythonOperator y BashOperator**

El `PythonOperator` se utiliza cuando la tarea requiere lÃ³gica de negocio, procesamiento de datos o validaciones mediante cÃ³digo Python.  
El `BashOperator` es mÃ¡s adecuado para ejecutar comandos del sistema operativo o tareas simples de preparaciÃ³n del entorno, como la creaciÃ³n de directorios o ejecuciÃ³n de scripts shell.

**b) Ventajas de definir dependencias explÃ­citas**

Definir dependencias explÃ­citas permite ejecutar tareas en paralelo, representar claramente el flujo mediante un grafo acÃ­clico, evitar ejecuciones incorrectas y facilitar el monitoreo, debugging y mantenimiento del pipeline.

---

### âœ… Resultados

- DAGs cargados correctamente sin errores.
- Ejecuciones exitosas de todas las tareas.
- Dependencias simples y complejas correctamente definidas.
- VisualizaciÃ³n y monitoreo desde Airflow Web UI.
- Logs accesibles para validaciÃ³n de ejecuciÃ³n.

---

### ğŸ§  Conclusiones

El desarrollo de estos DAGs permitiÃ³ consolidar los conceptos fundamentales de Apache Airflow, incluyendo la definiciÃ³n de workflows, uso de operadores, paralelismo, dependencias complejas y monitoreo de ejecuciones en un entorno Docker.

---
## ğŸ“‚ DAG 3: Pipeline con Sensores y Operador Personalizado

Este DAG incorpora **sensores y operadores personalizados**, simulando un escenario real de ingesta de datos dependiente de eventos externos.

- **DAG ID**: `pipeline_con_sensores_y_operador_custom`
- **Schedule**: `@hourly` (ejecutado manualmente durante pruebas)
- **Catchup**: deshabilitado

### Flujo del DAG
```
esperar_archivo_datos
        â†“
validar_datos_ventas
        â†“
procesar_datos_ventas
        â†“
generar_reporte
        â†“
limpiar_archivos
```

---

### ğŸ§  VerificaciÃ³n conceptual

**Â¿CuÃ¡ndo usar sensores?**  
Se utilizan sensores cuando la ejecuciÃ³n de un pipeline depende de una condiciÃ³n externa, como la llegada de archivos o la disponibilidad de datos.

**Â¿Ventajas de operadores personalizados?**  
Permiten encapsular lÃ³gica de negocio especÃ­fica, mejorar la reutilizaciÃ³n de cÃ³digo y mantener DAGs mÃ¡s limpios.

## DAG 4: Pipeline con Monitoreo y VerificaciÃ³n Conceptual

Este DAG estÃ¡ orientado a monitoreo avanzado, mÃ©tricas y alertas, simulando un pipeline productivo donde no solo importa ejecutar tareas, sino medir su comportamiento y reaccionar ante incidentes.

DAG ID: pipeline_monitorado

Schedule: ejecuciÃ³n manual (durante pruebas)

Catchup: deshabilitado

### Flujo del DAG
```
procesar_datos
        â†“
validar_metricas
        â†“
notificar_exito
        â†“
verificar_sla
```

---


## ğŸ§  VerificaciÃ³n conceptual
ğŸ”¹ Â¿QuÃ© mÃ©tricas son mÃ¡s importantes para monitorear en un pipeline de datos?

Las mÃ©tricas clave dependen del objetivo del pipeline, pero en un entorno productivo las mÃ¡s relevantes suelen ser:

Estado de las tareas (success / failed / retry)
Permite detectar fallos operacionales de forma inmediata.

DuraciÃ³n de ejecuciÃ³n por tarea y por DAG
Ayuda a identificar cuellos de botella y degradaciones de rendimiento.

Cumplimiento de SLA
Fundamental para pipelines crÃ­ticos que alimentan procesos de negocio o reporting.

Volumen de datos procesados
Permite detectar anomalÃ­as (datos incompletos, duplicados o caÃ­das abruptas).

Errores funcionales o de validaciÃ³n
Indicadores de problemas en la calidad de los datos.

ğŸ”¹ Â¿CÃ³mo decidir entre enviar alertas por Email vs Slack vs SMS?

La elecciÃ³n del canal de alertas debe basarse en criticidad, urgencia y contexto operativo:

Canal	CuÃ¡ndo usarlo
Email	Alertas informativas, reportes de Ã©xito, fallos no crÃ­ticos o resÃºmenes diarios.
Slack / Teams	Incidentes operativos que requieren atenciÃ³n rÃ¡pida del equipo tÃ©cnico. Ideal para entornos colaborativos.
SMS	Fallos crÃ­ticos en pipelines productivos, SLA incumplidos o eventos que requieren acciÃ³n inmediata fuera del horario laboral.

Buena prÃ¡ctica:
Combinar canales segÃºn severidad (por ejemplo, email para Ã©xito, Slack para warnings y SMS para errores crÃ­ticos).

### âœ… Resultados del DAG 4

Pipeline ejecutado correctamente.

MÃ©tricas registradas y evaluadas.

Alertas configuradas sin interrumpir el flujo principal.

SeparaciÃ³n clara entre lÃ³gica de negocio y monitoreo.

### ğŸ§  ConclusiÃ³n general

Con este cuarto DAG se completa un enfoque integral de Apache Airflow:

OrquestaciÃ³n bÃ¡sica, Dependencias complejas, Sensores y operadores personalizados, Monitoreo, mÃ©tricas y alertas

---

## VerificaciÃ³n conceptual â€“ Manejo de errores en pipelines

### Â¿QuÃ© diferencia hay entre un pipeline que falla silenciosamente y uno con buen manejo de errores?

Un pipeline que falla silenciosamente no registra ni comunica los errores ocurridos durante su ejecuciÃ³n, lo que puede provocar que el flujo continÃºe procesando datos invÃ¡lidos o incompletos. Esto dificulta el monitoreo, el debugging y la detecciÃ³n de fallos, aumentando el riesgo de generar resultados incorrectos sin que el problema sea evidente.

En contraste, un pipeline con buen manejo de errores detecta y captura explÃ­citamente las excepciones, registra informaciÃ³n clara sobre el fallo y detiene la ejecuciÃ³n cuando un error crÃ­tico compromete la calidad del dato. Este enfoque mejora la confiabilidad, trazabilidad y mantenibilidad del pipeline.

---

### Â¿CÃ³mo decidir cuÃ¡ndo reintentar versus abortar una ejecuciÃ³n?

La decisiÃ³n depende del tipo de error y su impacto en los datos:

- **Reintentar la ejecuciÃ³n** es adecuado cuando el error es transitorio, como fallas temporales de red, timeouts de APIs externas o problemas momentÃ¡neos de infraestructura.
- **Abortar la ejecuciÃ³n** es necesario cuando el error es lÃ³gico o crÃ­tico, como fallas de validaciÃ³n, esquemas incorrectos o datos corruptos, ya que continuar podrÃ­a propagar datos invÃ¡lidos a etapas posteriores.

Un pipeline robusto debe aplicar reintentos Ãºnicamente a errores transitorios y detener la ejecuciÃ³n ante errores que afecten la calidad o consistencia de los datos.

## ğŸ“Œ Autor

**FabiÃ¡n DÃ­az**  
Proyecto de aprendizaje en Ciencia de Datos / Data Engineering.
